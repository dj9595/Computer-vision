{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52581d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def apply_clahe(image_path):\n",
    "    # Read the image in grayscale\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Check if the image is loaded properly\n",
    "    if image is None:\n",
    "        print(f\"Error: Unable to load the image from {image_path}\")\n",
    "        return None\n",
    "\n",
    "    # Apply CLAHE\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    enhanced_image = clahe.apply(image)\n",
    "\n",
    "    return enhanced_image\n",
    "\n",
    "# Example usage\n",
    "image_path = r'C:\\Users\\MANI JAGAN\\Downloads\\extracted_images\\Data\\TCGA_FG_A60K_20040224\\TCGA_FG_A60K_20040224_1.tif'\n",
    "enhanced_image = apply_clahe(image_path)\n",
    "\n",
    "# Check if the enhancement was successful before saving\n",
    "if enhanced_image is not None:\n",
    "    cv2.imwrite('enhanced_image.tif', enhanced_image)\n",
    "else:\n",
    "    print(\"Image processing failed. No file saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e42def2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(image):\n",
    "    return image / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a928b995",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20, width_shift_range=0.2, height_shift_range=0.2, \n",
    "    zoom_range=0.2, horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Assuming `enhanced_image` is grayscale with shape (256, 256)\n",
    "# Adding both batch and channel dimensions to make the shape (1, 256, 256, 1)\n",
    "enhanced_image = np.expand_dims(enhanced_image, axis=-1)  # Add channel dimension (256, 256) -> (256, 256, 1)\n",
    "augmented_images = datagen.flow(np.expand_dims(enhanced_image, axis=0))  # Add batch dimension -> (1, 256, 256, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160d7e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def build_nested_unet(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "    # Downsampling path\n",
    "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    # Intermediate layers with additional nested connections would go here\n",
    "    \n",
    "    # Upsampling path\n",
    "    up1 = UpSampling2D(size=(2, 2))(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(up1)\n",
    "    \n",
    "    # Output layer\n",
    "    output = Conv2D(1, (1, 1), activation='sigmoid')(conv2)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    return model\n",
    "\n",
    "model = build_nested_unet((128, 128, 1))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb743cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Multiply, Activation, Add\n",
    "\n",
    "def attention_block(x, g, inter_channels):\n",
    "    theta_x = Conv2D(inter_channels, (2, 2), strides=(2, 2))(x)\n",
    "    phi_g = Conv2D(inter_channels, (1, 1), padding='same')(g)\n",
    "    concat_xg = Add()([theta_x, phi_g])\n",
    "    act_xg = Activation('relu')(concat_xg)\n",
    "    psi = Conv2D(1, (1, 1), padding='same')(act_xg)\n",
    "    psi = Activation('sigmoid')(psi)\n",
    "    upsample_psi = UpSampling2D(size=(2, 2))(psi)\n",
    "    return Multiply()([upsample_psi, x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf728c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    intersection = K.sum(y_true * y_pred)\n",
    "    return (2. * intersection) / (K.sum(y_true) + K.sum(y_pred) + K.epsilon())\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coefficient])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b140e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load dataset (for example, MNIST)\n",
    "(train_data, train_labels), (val_data, val_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the data\n",
    "train_data = train_data.astype('float32') / 255.0  # Normalize to [0, 1]\n",
    "val_data = val_data.astype('float32') / 255.0\n",
    "\n",
    "# Check if the data is 3D (height, width) and expand dimensions to (height, width, 1)\n",
    "if len(train_data.shape) == 3:\n",
    "    train_data = np.expand_dims(train_data, axis=-1)  # Shape: (num_samples, 28, 28, 1)\n",
    "\n",
    "if len(val_data.shape) == 3:\n",
    "    val_data = np.expand_dims(val_data, axis=-1)  # Shape: (num_samples, 28, 28, 1)\n",
    "\n",
    "# Resize images to (128, 128)\n",
    "train_data_resized = np.array([tf.image.resize(image, (128, 128)).numpy() for image in train_data])\n",
    "val_data_resized = np.array([tf.image.resize(image, (128, 128)).numpy() for image in val_data])\n",
    "\n",
    "# If images are grayscale, ensure they have a channel dimension (already done above)\n",
    "# The shape should now be (num_samples, 128, 128, 1)\n",
    "\n",
    "# Convert labels to categorical (one-hot encoding)\n",
    "train_labels = to_categorical(train_labels, num_classes=10)\n",
    "val_labels = to_categorical(val_labels, num_classes=10)\n",
    "\n",
    "# Now you can use train_data_resized and train_labels\n",
    "history = model.fit(train_data_resized, train_labels, epochs=50, validation_data=(val_data_resized, val_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655fb2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, File, UploadFile\n",
    "from tensorflow.keras.models import load_model\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "app = FastAPI()\n",
    "model = load_model('best_model.h5', custom_objects={'dice_coefficient': dice_coefficient})\n",
    "\n",
    "@app.post(\"/predict/\")\n",
    "async def predict(file: UploadFile = File(...)):\n",
    "    image = await file.read()\n",
    "    np_image = np.frombuffer(image, np.uint8)\n",
    "    img = cv2.imdecode(np_image, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    img_resized = cv2.resize(img, (128, 128))\n",
    "    img_normalized = img_resized / 255.0\n",
    "    img_input = np.expand_dims(img_normalized, axis=(0, -1))\n",
    "    \n",
    "    pred_mask = model.predict(img_input)\n",
    "    return {\"mask\": pred_mask.tolist()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0477cd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install fastapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51eb19be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-01 11:26:29.362 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-01 11:26:29.363 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-01 11:26:29.364 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-01 11:26:29.365 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-01 11:26:29.366 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-01 11:26:29.368 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import requests\n",
    "from PIL import Image\n",
    "\n",
    "st.title(\"Brain MRI Metastasis Segmentation\")\n",
    "\n",
    "uploaded_file = st.file_uploader(\"Choose an MRI image...\", type=[\"jpg\", \"png\", \"tif\"])\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    image = Image.open(uploaded_file)\n",
    "    st.image(image, caption='Uploaded MRI.', use_column_width=True)\n",
    "    \n",
    "    # Send the image to the backend API\n",
    "    files = {\"file\": uploaded_file.getvalue()}\n",
    "    response = requests.post(\"http://127.0.0.1:8000/predict/\", files=files)\n",
    "    \n",
    "    # Display the segmentation result\n",
    "    mask = np.array(response.json()['mask'])\n",
    "    st.image(mask, caption='Predicted Mask', use_column_width=True)\n",
    "    print(mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41140eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in c:\\users\\mani jagan\\anaconda3\\lib\\site-packages (1.38.0)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\mani jagan\\anaconda3\\lib\\site-packages (from streamlit) (17.0.0)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in c:\\users\\mani jagan\\anaconda3\\lib\\site-packages (from streamlit) (9.2.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\mani jagan\\anaconda3\\lib\\site-packages (from streamlit) (1.8.2)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\mani jagan\\anaconda3\\lib\\site-packages (from streamlit) (2.28.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\mani jagan\\anaconda3\\lib\\site-packages (from streamlit) (8.0.4)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\mani jagan\\anaconda3\\lib\\site-packages (from streamlit) (13.8.1)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\mani jagan\\anaconda3\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\mani jagan\\anaconda3\\lib\\site-packages (from streamlit) (21.3)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\mani jagan\\anaconda3\\lib\\site-packages (from streamlit) (3.1.43)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\mani jagan\\anaconda3\\lib\\site-packages (from streamlit) (5.4.1)\n",
      "Requirement already satisfied: numpy<3,>=1.20 in c:\\users\\mani jagan\\anaconda3\\lib\\site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\mani jagan\\anaconda3\\lib\\site-packages (from streamlit) (6.1)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\mani jagan\\anaconda3\\lib\\site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: watchdog<5,>=2.1.5 in c:\\users\\mani jagan\\anaconda3\\lib\\site-packages (from streamlit) (2.1.6)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in c:\\users\\mani jagan\\anaconda3\\lib\\site-packages (from streamlit) (4.12.2)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in c:\\users\\mani jagan\\anaconda3\\lib\\site-packages (from streamlit) (8.5.0)\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in c:\\users\\mani jagan\\anaconda3\\lib\\site-packages (from streamlit) (1.4.4)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\mani jagan\\anaconda3\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\users\\mani jagan\\anaconda3\\lib\\site-packages (from streamlit) (4.25.5)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\mani jagan\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.16.0)\n",
      "Requirement already satisfied: narwhals>=1.5.2 in c:\\users\\mani jagan\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (1.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mani jagan\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (2.11.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\mani jagan\\anaconda3\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.5)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\mani jagan\\anaconda3\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\mani jagan\\anaconda3\\lib\\site-packages (from packaging<25,>=20->streamlit) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\mani jagan\\anaconda3\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mani jagan\\anaconda3\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2022.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\mani jagan\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mani jagan\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mani jagan\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mani jagan\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (1.26.11)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\mani jagan\\anaconda3\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\mani jagan\\anaconda3\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\mani jagan\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\mani jagan\\anaconda3\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.0.1)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\mani jagan\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\mani jagan\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (21.4.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\mani jagan\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mani jagan\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbb5ef4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5294664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46e51f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
